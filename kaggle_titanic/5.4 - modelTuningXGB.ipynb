{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:05:39.302948Z",
     "start_time": "2018-12-07T11:05:34.732891Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'G:/work/GitHub/ml_baseline_things/functions/')\n",
    "import GridSearchCVcustom as GSC\n",
    "import featureEngineringFunctions as fef\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dirPath = '2-featuresPack/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:05:39.527098Z",
     "start_time": "2018-12-07T11:05:39.304945Z"
    }
   },
   "outputs": [],
   "source": [
    "#featuresFromOtherSolutions = ['Survived','Pclass','Sex','Family_Size','Family_Survival','Fare_Bin','Age_Bin']\n",
    "\n",
    "featureList = [\n",
    "#'PassengerId',\n",
    "#'Survived',\n",
    "#'AGE_cont',\n",
    "'AgeBin_LE',\n",
    "#'Age-Class_cont',\n",
    "#'Deck_LE',\n",
    "#'Deck_OHE',\n",
    "'FamilySize_LE',\n",
    "#'Fare_cont',\n",
    "'FareBin_LE',\n",
    "#'HasBloodRelatives_LE',\n",
    "#'HasWifeHasb_LE',\n",
    "#'IsAlone_LE',\n",
    "#'Parch_LE',\n",
    "'Pclass_LE',\n",
    "'Sex_LE',\n",
    "#'Sex_OHE',\n",
    "#'SibSp_LE',\n",
    "#'Title_LE',\n",
    "#'Title_OHE',\n",
    "'FamilySurvival_bin'\n",
    "]\n",
    "#features = ['Survived','Pclass','Sex','Family_Size','Family_Survival','Fare_Bin','Age_Bin']\n",
    "\n",
    "trainVStest = 891\n",
    "dataAll = fef.create_dataset_from_features (featureList, dirPath)\n",
    "dataTrain = fef.create_dataset_from_features (featureList, dirPath)[:trainVStest]\n",
    "dataTrainTarget =fef.create_dataset_from_features (['Survived'], dirPath)[:trainVStest]\n",
    "\n",
    "dataTrainScaled = StandardScaler().fit(dataAll).transform(dataTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:05:39.709215Z",
     "start_time": "2018-12-07T11:05:39.529095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "        max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "        n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=None, silent=True, subsample=1)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check available params\n",
    "pipeline = GSC.get_pipeline_1step(xgb.XGBClassifier(n_jobs=-1))\n",
    "pipeline.named_steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:09:21.410678Z",
     "start_time": "2018-12-07T11:09:21.219546Z"
    }
   },
   "outputs": [],
   "source": [
    "RS = 100\n",
    "score = \"roc_auc\"\n",
    "n_splits = 5\n",
    "nSamples = len(dataTrain)\n",
    "cvShuffle = True\n",
    "paramGrid = {'clf': [xgb.XGBClassifier(n_jobs=-1)],\n",
    "              'clf__random_state': [RS],\n",
    "              'clf__class_weight': ['balanced'],\n",
    "              'clf__n_estimators': [10, 100, 250, 500, 750, 1000],\n",
    "              'clf__max_depth': [1, 2, 4],\n",
    "              'clf__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.5]\n",
    "             }\n",
    "cv = StratifiedKFold(n_splits=n_splits, random_state=RS, shuffle=cvShuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-Scaled + StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:06:51.483092Z",
     "start_time": "2018-12-07T11:05:39.895342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations exist for provided gridSearch params: 90\n",
      "These steps available to be performed:\n",
      "v Iter 1: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 2: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 3: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 4: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 5: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 6: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 7: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 8: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 9: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 10: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 11: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 12: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 13: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 14: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 15: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 16: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 17: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 18: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 19: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 20: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 21: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 22: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 23: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 24: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 25: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 26: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 27: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 28: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 29: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 30: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 31: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 32: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 33: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 34: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 35: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 36: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 37: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 38: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 39: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 40: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 41: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 42: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 43: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 44: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 45: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 46: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 47: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 48: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 49: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 50: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 51: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 52: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 53: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 54: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 55: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 56: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 57: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 58: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 59: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 60: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 61: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 62: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 63: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 64: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 65: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 66: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 67: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 68: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 69: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 70: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 71: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 72: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 73: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 74: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 75: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 76: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 77: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 78: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 79: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 80: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 81: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 82: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 83: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 84: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 85: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 86: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 87: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 88: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 89: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 90: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "\n",
      "\n",
      "--==Calculations...==--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best result = 0.76681 (std = 0.02215) during 15.0 [secs] (iter = 1) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 10), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.83729 (std = 0.02636) during 8.0 [secs] (iter = 2) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 100), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.86299 (std = 0.0216) during 0.0 [secs] (iter = 3) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 250), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.86836 (std = 0.01988) during 0.0 [secs] (iter = 4) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 86\n",
      "Average time for iteration [mins]: 0.1\n",
      "Job will be done in (approximately) [mins] : 8.2\n",
      "\n",
      "New best result = 0.87033 (std = 0.02013) during 1.0 [secs] (iter = 5) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 750), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.87343 (std = 0.0227) during 1.0 [secs] (iter = 6) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 1000), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 81\n",
      "Average time for iteration [mins]: 0.05\n",
      "Job will be done in (approximately) [mins] : 3.7\n",
      "\n",
      "New best result = 0.88387 (std = 0.01941) during 1.0 [secs] (iter = 10) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 2), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.88716 (std = 0.01842) during 1.0 [secs] (iter = 11) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 2), ('clf__n_estimators', 750), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 76\n",
      "Average time for iteration [mins]: 0.03\n",
      "Job will be done in (approximately) [mins] : 2.5\n",
      "\n",
      "New best result = 0.88717 (std = 0.01621) during 1.0 [secs] (iter = 16) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 4), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 71\n",
      "Average time for iteration [mins]: 0.03\n",
      "Job will be done in (approximately) [mins] : 2.0\n",
      "\n",
      "Iterations to perform: 66\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 1.6\n",
      "\n",
      "Iterations to perform: 61\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 1.3\n",
      "\n",
      "Iterations to perform: 56\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 1.0\n",
      "\n",
      "Iterations to perform: 51\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.9\n",
      "\n",
      "Iterations to perform: 46\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.8\n",
      "\n",
      "Iterations to perform: 41\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.6\n",
      "\n",
      "New best result = 0.88741 (std = 0.01611) during 0.0 [secs] (iter = 50) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.05), ('clf__max_depth', 4), ('clf__n_estimators', 100), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 36\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.6\n",
      "\n",
      "Iterations to perform: 31\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "Iterations to perform: 26\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "Iterations to perform: 21\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.3\n",
      "\n",
      "Iterations to perform: 16\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations to perform: 11\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.1\n",
      "\n",
      "Iterations to perform: 6\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.1\n",
      "\n",
      "Iterations to perform: 1\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.0\n",
      "\n",
      "Congrats! All DONE. Total time is [mins]: 1.19\n",
      "BestIter was 50, bestScore = 0.8874091492128635, bestScoreParams = {'clf': XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
      "       colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=100,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)}\n",
      "bestScore = 0.8874091492128635\n",
      "BestScoreParams = {'clf': XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
      "       colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=100,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)}\n"
     ]
    }
   ],
   "source": [
    "bestScore1, bestScoreParams1, bestIter1 = GSC.GridSearchCVcustom(pipeline, paramGrid, \n",
    "                                                              dataTrain, dataTrainTarget,\n",
    "                                                              cv=cv, n_jobs = -1, scoring = score, pre_dispatch=2,\n",
    "                                                              showSteps=True, itersToPerform ='All')\n",
    "print ('bestScore = {}\\nBestScoreParams = {}'.format(bestScore1, bestScoreParams1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled + StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:07:40.325372Z",
     "start_time": "2018-12-07T11:06:51.485594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations exist for provided gridSearch params: 90\n",
      "These steps available to be performed:\n",
      "v Iter 1: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 2: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 3: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 4: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 5: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 6: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 7: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 8: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 9: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 10: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 11: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 12: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 13: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 14: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 15: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 16: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 17: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 18: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 19: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 20: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 21: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 22: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 23: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 24: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 25: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 26: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 27: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 28: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 29: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 30: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 31: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 32: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 33: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 34: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 35: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 36: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 37: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 38: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 39: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 40: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 41: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 42: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 43: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 44: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 45: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 46: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 47: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 48: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 49: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 50: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 51: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 52: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 53: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 54: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 55: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 56: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 57: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 58: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 59: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 60: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 61: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 62: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 63: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 64: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 65: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 66: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 67: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 68: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 69: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 70: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 71: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 72: clf__class_weight: balanced  clf__learning_rate: 0.1  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 73: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 74: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 75: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 76: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 77: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 78: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 1  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 79: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 80: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 81: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 82: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 83: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 84: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 2  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "v Iter 85: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 86: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 87: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 250  clf__random_state: 100  \n",
      "v Iter 88: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 89: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 750  clf__random_state: 100  \n",
      "v Iter 90: clf__class_weight: balanced  clf__learning_rate: 0.5  clf__max_depth: 4  clf__n_estimators: 1000  clf__random_state: 100  \n",
      "\n",
      "\n",
      "--==Calculations...==--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best result = 0.76681 (std = 0.02215) during 0.0 [secs] (iter = 1) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 10), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.83729 (std = 0.02636) during 0.0 [secs] (iter = 2) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 100), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.86299 (std = 0.0216) during 0.0 [secs] (iter = 3) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 250), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.86836 (std = 0.01988) during 0.0 [secs] (iter = 4) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 86\n",
      "Average time for iteration [mins]: 0.0\n",
      "Job will be done in (approximately) [mins] : 0.3\n",
      "\n",
      "New best result = 0.87033 (std = 0.02013) during 1.0 [secs] (iter = 5) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 750), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.87343 (std = 0.0227) during 1.0 [secs] (iter = 6) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 1), ('clf__n_estimators', 1000), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 81\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "New best result = 0.88387 (std = 0.01941) during 1.0 [secs] (iter = 10) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 2), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "New best result = 0.88716 (std = 0.01842) during 1.0 [secs] (iter = 11) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 2), ('clf__n_estimators', 750), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 76\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "New best result = 0.88717 (std = 0.01621) during 1.0 [secs] (iter = 16) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.01), ('clf__max_depth', 4), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 71\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.6\n",
      "\n",
      "Iterations to perform: 66\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "Iterations to perform: 61\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "Iterations to perform: 56\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "Iterations to perform: 51\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "Iterations to perform: 46\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "Iterations to perform: 41\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.3\n",
      "\n",
      "New best result = 0.88741 (std = 0.01611) during 0.0 [secs] (iter = 50) for search with params \n",
      "dict_items([('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.05), ('clf__max_depth', 4), ('clf__n_estimators', 100), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 36\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.3\n",
      "\n",
      "Iterations to perform: 31\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.3\n",
      "\n",
      "Iterations to perform: 26\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n",
      "Iterations to perform: 21\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n",
      "Iterations to perform: 16\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations to perform: 11\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.1\n",
      "\n",
      "Iterations to perform: 6\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.0\n",
      "\n",
      "Iterations to perform: 1\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.0\n",
      "\n",
      "Congrats! All DONE. Total time is [mins]: 0.81\n",
      "BestIter was 50, bestScore = 0.8874091492128635, bestScoreParams = {'clf': XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
      "       colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=100,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)}\n",
      "bestScore = 0.8874091492128635\n",
      "BestScoreParams = {'clf': XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
      "       colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=100,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)}\n"
     ]
    }
   ],
   "source": [
    "bestScore2, bestScoreParams2, bestIter2 = GSC.GridSearchCVcustom(pipeline, paramGrid, \n",
    "                                                              dataTrainScaled, dataTrainTarget,\n",
    "                                                              cv=cv, n_jobs = -1, scoring = score, pre_dispatch=2,\n",
    "                                                              showSteps=True, itersToPerform ='All')\n",
    "print ('bestScore = {}\\nBestScoreParams = {}'.format(bestScore2, bestScoreParams2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:58:56.569763Z",
     "start_time": "2018-12-01T21:58:56.387643Z"
    }
   },
   "source": [
    "## Pure GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:11:26.670587Z",
     "start_time": "2018-12-07T11:10:10.185921Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   59.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8874134718911294\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
      "       max_depth=4, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=100, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(n_jobs=-1)\n",
    "\n",
    "params = {\n",
    "              'random_state': [RS],\n",
    "              #'class_weight': ['balanced'],\n",
    "              'n_estimators': [10, 100, 250, 500, 750, 1000],\n",
    "              'max_depth': [1, 2, 4],\n",
    "              'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.5]\n",
    "             }\n",
    "\n",
    "# Using ROC_AUC as metric has a better result than using accuracy. \n",
    "gs = GridSearchCV(clf, param_grid= params, cv = cv, n_jobs = -1 ,scoring = score,verbose=2)\n",
    "gs.fit(dataTrainScaled, dataTrainTarget)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:29:01.937229Z",
     "start_time": "2018-12-07T11:29:01.764112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=100, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:28:24.831725Z",
     "start_time": "2018-12-07T11:28:24.660611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=5, random_state=100, shuffle=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T22:01:06.713399Z",
     "start_time": "2018-11-30T22:01:06.539270Z"
    }
   },
   "source": [
    "## save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:31:05.196971Z",
     "start_time": "2018-12-07T11:31:04.898774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=100, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = bestScoreParams2['clf']\n",
    "model = gs.best_estimator_\n",
    "model.fit(dataTrainScaled, dataTrainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T11:31:15.561065Z",
     "start_time": "2018-12-07T11:31:15.355929Z"
    }
   },
   "outputs": [],
   "source": [
    "@comment_this_line_if_ready\n",
    "from datetime import datetime\n",
    "_ = joblib.dump([model, featureList], \n",
    "            open('modelsTrained/modelXGB--{}.pkl'.format(datetime.now().strftime(\"%Y-%m-%d--%H-%M\")), 'wb'), 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
