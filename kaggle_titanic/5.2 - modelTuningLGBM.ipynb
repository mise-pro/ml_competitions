{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T20:57:51.082963Z",
     "start_time": "2018-11-30T20:57:46.762940Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'G:/work/GitHub/ml_baseline_things/functions/')\n",
    "import GridSearchCVcustom as GSC\n",
    "import featureEngineringFunctions as fef\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T20:57:51.276091Z",
     "start_time": "2018-11-30T20:57:51.084961Z"
    }
   },
   "outputs": [],
   "source": [
    "featureListLElev = [\n",
    "'AGE_lev_train',\n",
    "'Age-Class_cnt_train',\n",
    "'Deck_LE_train',\n",
    "'FamilySize_cnt_train',\n",
    "'Fare_lev_train',\n",
    "#'HasBloodRelatives_train',\n",
    "#'HasWifeHasb_train',\n",
    "#'IsAlone_train',\n",
    "'Pclass_cnt_train',\n",
    "'SEX_LE_train',\n",
    "'Title_LE_train'\n",
    "]\n",
    "dataTrain = fef.create_dataset_from_features (featureListLElev, '2.1-featuresPack/')\n",
    "dataTrainTarget =fef.create_dataset_from_features (['Survived_train'], '2.1-featuresPack/')\n",
    "\n",
    "dataTrainScaled = StandardScaler().fit_transform(dataTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T20:57:51.453208Z",
     "start_time": "2018-11-30T20:57:51.278092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "         importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "         min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "         n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "         random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "         subsample=1.0, subsample_for_bin=200000, subsample_freq=0)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check available params\n",
    "pipeline = GSC.get_pipeline_1step(LGBMClassifier())\n",
    "pipeline.named_steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T20:57:51.631329Z",
     "start_time": "2018-11-30T20:57:51.455210Z"
    }
   },
   "outputs": [],
   "source": [
    "RS = 100\n",
    "n_splits = 25\n",
    "nSamples = len(dataTrain)\n",
    "cvShuffle = True\n",
    "paramGrid = {'clf': [LGBMClassifier()],\n",
    "              'clf__random_state': [RS],\n",
    "              'clf__class_weight': ['balanced'],\n",
    "              'clf__n_estimators': [10, 50, 100, 200, 350, 500],\n",
    "              'clf__max_depth': [1, 2, 4],\n",
    "              'clf__learning_rate': [0.005, 0.01, 0.02, 0.05]\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-Scaled + StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T20:58:58.816737Z",
     "start_time": "2018-11-30T20:57:51.633329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations exist for provided gridSearch params: 72\n",
      "These steps available to be performed:\n",
      "v Iter 1: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 2: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 3: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 4: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 5: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 6: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 7: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 8: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 9: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 10: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 11: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 12: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 13: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 14: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 15: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 16: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 17: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 18: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 19: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 20: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 21: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 22: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 23: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 24: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 25: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 26: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 27: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 28: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 29: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 30: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 31: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 32: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 33: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 34: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 35: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 36: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 37: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 38: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 39: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 40: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 41: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 42: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 43: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 44: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 45: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 46: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 47: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 48: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 49: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 50: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 51: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 52: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 53: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 54: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 55: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 56: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 57: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 58: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 59: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 60: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 61: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 62: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 63: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 64: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 65: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 66: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 67: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 68: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 69: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 70: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 71: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 72: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "\n",
      "\n",
      "--==Calculations...==--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best result = 0.78662 (std = 0.05995) during 18.0 [secs] (iter = 1) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.005), ('clf__max_depth', 1), ('clf__n_estimators', 10), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 71\n",
      "Average time for iteration [mins]: 0.3\n",
      "Job will be done in (approximately) [mins] : 20.9\n",
      "\n",
      "New best result = 0.7943 (std = 0.06295) during 1.0 [secs] (iter = 6) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.005), ('clf__max_depth', 1), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 66\n",
      "Average time for iteration [mins]: 0.06\n",
      "Job will be done in (approximately) [mins] : 3.8\n",
      "\n",
      "New best result = 0.82573 (std = 0.05049) during 1.0 [secs] (iter = 11) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.005), ('clf__max_depth', 2), ('clf__n_estimators', 350), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 61\n",
      "Average time for iteration [mins]: 0.04\n",
      "Job will be done in (approximately) [mins] : 2.1\n",
      "\n",
      "New best result = 0.83246 (std = 0.05314) during 1.0 [secs] (iter = 12) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.005), ('clf__max_depth', 2), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 56\n",
      "Average time for iteration [mins]: 0.03\n",
      "Job will be done in (approximately) [mins] : 1.5\n",
      "\n",
      "Iterations to perform: 51\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 1.2\n",
      "\n",
      "Iterations to perform: 46\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 1.0\n",
      "\n",
      "Iterations to perform: 41\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.8\n",
      "\n",
      "Iterations to perform: 36\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.7\n",
      "\n",
      "Iterations to perform: 31\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "Iterations to perform: 26\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "Iterations to perform: 21\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.3\n",
      "\n",
      "Iterations to perform: 16\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n",
      "Iterations to perform: 11\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n",
      "Iterations to perform: 6\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.1\n",
      "\n",
      "New best result = 0.83814 (std = 0.05442) during 1.0 [secs] (iter = 71) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.05), ('clf__max_depth', 4), ('clf__n_estimators', 350), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 1\n",
      "Average time for iteration [mins]: 0.02\n",
      "Job will be done in (approximately) [mins] : 0.0\n",
      "\n",
      "New best result = 0.83929 (std = 0.05664) during 2.0 [secs] (iter = 72) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.05), ('clf__max_depth', 4), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Congrats! All DONE. Total time is [mins]: 1.12\n",
      "BestIter was 72, bestScore = 0.8392866479925304, bestScoreParams = {'clf': LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
      "        colsample_bytree=1.0, importance_type='split', learning_rate=0.05,\n",
      "        max_depth=4, min_child_samples=20, min_child_weight=0.001,\n",
      "        min_split_gain=0.0, n_estimators=500, n_jobs=-1, num_leaves=31,\n",
      "        objective=None, random_state=100, reg_alpha=0.0, reg_lambda=0.0,\n",
      "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)}\n",
      "bestScore = 0.8392866479925304\n",
      "BestScoreParams = {'clf': LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
      "        colsample_bytree=1.0, importance_type='split', learning_rate=0.05,\n",
      "        max_depth=4, min_child_samples=20, min_child_weight=0.001,\n",
      "        min_split_gain=0.0, n_estimators=500, n_jobs=-1, num_leaves=31,\n",
      "        objective=None, random_state=100, reg_alpha=0.0, reg_lambda=0.0,\n",
      "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=n_splits, random_state=RS, shuffle=cvShuffle)\n",
    "\n",
    "bestScore1, bestScoreParams1, bestIter1 = GSC.GridSearchCVcustom(pipeline, paramGrid, \n",
    "                                                              dataTrain[:nSamples], dataTrainTarget[:nSamples],\n",
    "                                                              cv=cv, n_jobs = -1, pre_dispatch=2,\n",
    "                                                              showSteps=True, itersToPerform ='All')\n",
    "print ('bestScore = {}\\nBestScoreParams = {}'.format(bestScore1, bestScoreParams1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled + StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T20:59:43.165390Z",
     "start_time": "2018-11-30T20:58:58.818738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations exist for provided gridSearch params: 72\n",
      "These steps available to be performed:\n",
      "v Iter 1: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 2: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 3: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 4: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 5: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 6: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 7: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 8: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 9: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 10: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 11: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 12: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 13: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 14: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 15: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 16: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 17: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 18: clf__class_weight: balanced  clf__learning_rate: 0.005  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 19: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 20: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 21: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 22: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 23: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 24: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 25: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 26: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 27: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 28: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 29: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 30: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 31: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 32: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 33: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 34: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 35: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 36: clf__class_weight: balanced  clf__learning_rate: 0.01  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 37: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 38: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 39: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 40: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 41: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 42: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 43: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 44: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 45: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 46: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 47: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 48: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 49: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 50: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 51: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 52: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 53: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 54: clf__class_weight: balanced  clf__learning_rate: 0.02  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 55: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 56: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 57: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 58: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 59: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 60: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 1  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 61: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 62: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 63: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 64: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 65: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 66: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 2  clf__n_estimators: 500  clf__random_state: 100  \n",
      "v Iter 67: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 10  clf__random_state: 100  \n",
      "v Iter 68: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 50  clf__random_state: 100  \n",
      "v Iter 69: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 100  clf__random_state: 100  \n",
      "v Iter 70: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 200  clf__random_state: 100  \n",
      "v Iter 71: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 350  clf__random_state: 100  \n",
      "v Iter 72: clf__class_weight: balanced  clf__learning_rate: 0.05  clf__max_depth: 4  clf__n_estimators: 500  clf__random_state: 100  \n",
      "\n",
      "\n",
      "--==Calculations...==--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best result = 0.78662 (std = 0.05995) during 0.0 [secs] (iter = 1) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.005), ('clf__max_depth', 1), ('clf__n_estimators', 10), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 71\n",
      "Average time for iteration [mins]: 0.0\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n",
      "New best result = 0.7943 (std = 0.06295) during 1.0 [secs] (iter = 6) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.005), ('clf__max_depth', 1), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 66\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "New best result = 0.82573 (std = 0.05049) during 1.0 [secs] (iter = 11) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.005), ('clf__max_depth', 2), ('clf__n_estimators', 350), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 61\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "New best result = 0.83246 (std = 0.05314) during 1.0 [secs] (iter = 12) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.005), ('clf__max_depth', 2), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 56\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "Iterations to perform: 51\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.5\n",
      "\n",
      "Iterations to perform: 46\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "Iterations to perform: 41\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "Iterations to perform: 36\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.4\n",
      "\n",
      "Iterations to perform: 31\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.3\n",
      "\n",
      "Iterations to perform: 26\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n",
      "Iterations to perform: 21\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n",
      "Iterations to perform: 16\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.2\n",
      "\n",
      "Iterations to perform: 11\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.1\n",
      "\n",
      "Iterations to perform: 6\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.1\n",
      "\n",
      "New best result = 0.83814 (std = 0.05442) during 1.0 [secs] (iter = 71) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.05), ('clf__max_depth', 4), ('clf__n_estimators', 350), ('clf__random_state', 100)])\n",
      "\n",
      "Iterations to perform: 1\n",
      "Average time for iteration [mins]: 0.01\n",
      "Job will be done in (approximately) [mins] : 0.0\n",
      "\n",
      "New best result = 0.83929 (std = 0.05664) during 2.0 [secs] (iter = 72) for search with params \n",
      "dict_items([('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)), ('clf__class_weight', 'balanced'), ('clf__learning_rate', 0.05), ('clf__max_depth', 4), ('clf__n_estimators', 500), ('clf__random_state', 100)])\n",
      "\n",
      "Congrats! All DONE. Total time is [mins]: 0.74\n",
      "BestIter was 72, bestScore = 0.8392866479925304, bestScoreParams = {'clf': LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
      "        colsample_bytree=1.0, importance_type='split', learning_rate=0.05,\n",
      "        max_depth=4, min_child_samples=20, min_child_weight=0.001,\n",
      "        min_split_gain=0.0, n_estimators=500, n_jobs=-1, num_leaves=31,\n",
      "        objective=None, random_state=100, reg_alpha=0.0, reg_lambda=0.0,\n",
      "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)}\n",
      "bestScore = 0.8392866479925304\n",
      "BestScoreParams = {'clf': LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
      "        colsample_bytree=1.0, importance_type='split', learning_rate=0.05,\n",
      "        max_depth=4, min_child_samples=20, min_child_weight=0.001,\n",
      "        min_split_gain=0.0, n_estimators=500, n_jobs=-1, num_leaves=31,\n",
      "        objective=None, random_state=100, reg_alpha=0.0, reg_lambda=0.0,\n",
      "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "        subsample_freq=0)}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=n_splits, random_state=RS, shuffle=cvShuffle)\n",
    "\n",
    "bestScore2, bestScoreParams2, bestIter2 = GSC.GridSearchCVcustom(pipeline, paramGrid, \n",
    "                                                              dataTrainScaled[:nSamples], dataTrainTarget[:nSamples],\n",
    "                                                              cv=cv, n_jobs = -1, pre_dispatch=2,\n",
    "                                                              showSteps=True, itersToPerform ='All')\n",
    "print ('bestScore = {}\\nBestScoreParams = {}'.format(bestScore2, bestScoreParams2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T22:01:06.713399Z",
     "start_time": "2018-11-30T22:01:06.539270Z"
    }
   },
   "source": [
    "## save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T22:02:33.018770Z",
     "start_time": "2018-11-30T22:02:32.714568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "        colsample_bytree=1.0, importance_type='split', learning_rate=0.05,\n",
       "        max_depth=4, min_child_samples=20, min_child_weight=0.001,\n",
       "        min_split_gain=0.0, n_estimators=500, n_jobs=-1, num_leaves=31,\n",
       "        objective=None, random_state=100, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bestScoreParams2['clf']\n",
    "model.fit(dataTrain[:nSamples], dataTrainTarget[:nSamples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T22:04:01.088623Z",
     "start_time": "2018-11-30T22:03:57.769196Z"
    }
   },
   "outputs": [],
   "source": [
    "#@comment_this_line_if_ready\n",
    "from datetime import datetime\n",
    "_ = joblib.dump([model, list(dataTrain.columns)], \n",
    "            open('modelsTrained/modelLGB--{}.pkl'.format(datetime.now().strftime(\"%Y-%m-%d--%H-%M\")), 'wb'), 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
