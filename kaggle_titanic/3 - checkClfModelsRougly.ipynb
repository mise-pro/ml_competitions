{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T10:36:18.773067Z",
     "start_time": "2018-12-01T10:36:14.294405Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'G:/work/GitHub/ml_baseline_things/functions/')\n",
    "\n",
    "import CheckClassificationModels as ccm\n",
    "import supportFunctions as sf\n",
    "import featureEngineringFunctions as fef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T10:36:18.975188Z",
     "start_time": "2018-12-01T10:36:18.775055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (891, 12); Test (418, 11); Total (1309, 12).\n"
     ]
    }
   ],
   "source": [
    "dataRawTrain, dataRawTest, _ = sf.load_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survived_train \n",
    "AGE_cnt_train\n",
    "Age_lev_train\n",
    "Age-Class_cnt_train\n",
    "Deck_LE_train\n",
    "Deck_OHE_train\n",
    "FamilySize_cnt_train\n",
    "Fare_cnt_train\n",
    "Fare_lev_train\n",
    "HasBloodRelatives_train\n",
    "HasWifeHasb_train\n",
    "IsAlone_train\n",
    "PassengerId_train\n",
    "Pclass_cnt_train\n",
    "Pclass_OHE_train\n",
    "SEX_LE_train\n",
    "SEX_OHE_train\n",
    "Title_LE_train\n",
    "Title_OHE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T10:36:19.297510Z",
     "start_time": "2018-12-01T10:36:18.977189Z"
    }
   },
   "outputs": [],
   "source": [
    "featureListLE = [\n",
    "'AGE_cnt_train',\n",
    "'Age-Class_cnt_train',\n",
    "'Deck_LE_train',\n",
    "'FamilySize_cnt_train',\n",
    "'Fare_cnt_train',\n",
    "'HasBloodRelatives_train',\n",
    "'HasWifeHasb_train',\n",
    "'IsAlone_train',\n",
    "'Pclass_cnt_train',\n",
    "'SEX_LE_train',\n",
    "'Title_LE_train'\n",
    "]\n",
    "dataTrainLE = fef.create_dataset_from_features (featureListLE, '2.1-featuresPack/')\n",
    "#dataTrainLE\n",
    "\n",
    "featureListLElev = [\n",
    "'AGE_lev_train',\n",
    "'Age-Class_cnt_train',\n",
    "'Deck_LE_train',\n",
    "'FamilySize_cnt_train',\n",
    "'Fare_lev_train',\n",
    "'HasBloodRelatives_train',\n",
    "'HasWifeHasb_train',\n",
    "'IsAlone_train',\n",
    "'Pclass_cnt_train',\n",
    "'SEX_LE_train',\n",
    "'Title_LE_train'\n",
    "]\n",
    "dataTrainLElev = fef.create_dataset_from_features (featureListLElev, '2.1-featuresPack/')\n",
    "#dataTrainLE\n",
    "\n",
    "featureListOHE = [\n",
    "'AGE_cnt_train',\n",
    "'Age-Class_cnt_train',\n",
    "'Deck_OHE_train',\n",
    "'FamilySize_cnt_train',\n",
    "'Fare_cnt_train',\n",
    "'HasBloodRelatives_train',\n",
    "'HasWifeHasb_train',\n",
    "'IsAlone_train',\n",
    "'Pclass_cnt_train',\n",
    "'SEX_OHE_train',\n",
    "'Title_OHE_train'\n",
    "]\n",
    "dataTrainOHE = fef.create_dataset_from_features (featureListOHE, '2.1-featuresPack/')\n",
    "#dataTrainOHE\n",
    "\n",
    "featureListOHElev = [\n",
    "'AGE_lev_train',\n",
    "'Age-Class_cnt_train',\n",
    "'Deck_OHE_train',\n",
    "'FamilySize_cnt_train',\n",
    "'Fare_lev_train',\n",
    "'HasBloodRelatives_train',\n",
    "'HasWifeHasb_train',\n",
    "'IsAlone_train',\n",
    "'Pclass_cnt_train',\n",
    "'SEX_OHE_train',\n",
    "'Title_OHE_train'\n",
    "]\n",
    "dataTrainOHElev = fef.create_dataset_from_features (featureListOHElev, '2.1-featuresPack/')\n",
    "dataTrainOHElev\n",
    "\n",
    "datasetPack = [dataTrainLE, dataTrainOHE, dataTrainLElev, dataTrainOHElev]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## задача этого ноута - построить кроссвалидацию + все начальные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T10:36:19.480527Z",
     "start_time": "2018-12-01T10:36:19.299406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if balanced or not: 0.3838383838383838\n"
     ]
    }
   ],
   "source": [
    "#check if balanced or not\n",
    "print ('check if balanced or not: {}'.format(float(sum(dataRawTrain.Survived))/len(dataRawTrain.Survived)))\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators\n",
    "# checklist CV strategy\n",
    "# данные приходят из i.i.d распределения?\n",
    "# данные имеют временную зависимоть?\n",
    "# данные имеют зависимость от группы? например, строки можно объединить в группы, где целевая переменная генерится по своему закону по каждой группе?\n",
    "# может выделить искуственную группу от признака, от которого есть большая корреляция?\n",
    "# есть ли смежные данные?\n",
    "\n",
    "# TODO metrics should be choosen optimally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T10:47:11.709875Z",
     "start_time": "2018-12-01T10:36:33.263804Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations will be perform (for each featureSet) = 12\n",
      "Iteration done in 0.34 [mins]\n",
      "Iteration done in 0.05 [mins]\n",
      "Iteration done in 0.05 [mins]\n",
      "Iteration done in 0.09 [mins]\n",
      "Iteration done in 0.07 [mins]\n",
      "Iteration done in 0.13 [mins]\n",
      "Iteration done in 0.13 [mins]\n",
      "Iteration done in 0.3 [mins]\n",
      "Iteration done in 0.18 [mins]\n",
      "Iteration done in 0.45 [mins]\n",
      "Iteration done in 0.28 [mins]\n",
      "Iteration done in 0.78 [mins]\n",
      "Congrats! All DONE. Total time is [mins]: 2.83\n",
      "All files were successfully saved to disk...\n",
      "\n",
      "Total iterations will be perform (for each featureSet) = 12\n",
      "Iteration done in 0.03 [mins]\n",
      "Iteration done in 0.05 [mins]\n",
      "Iteration done in 0.05 [mins]\n",
      "Iteration done in 0.09 [mins]\n",
      "Iteration done in 0.07 [mins]\n",
      "Iteration done in 0.14 [mins]\n",
      "Iteration done in 0.15 [mins]\n",
      "Iteration done in 0.34 [mins]\n",
      "Iteration done in 0.22 [mins]\n",
      "Iteration done in 0.55 [mins]\n",
      "Iteration done in 0.37 [mins]\n",
      "Iteration done in 0.93 [mins]\n",
      "Congrats! All DONE. Total time is [mins]: 3.02\n",
      "All files were successfully saved to disk...\n",
      "\n",
      "Total iterations will be perform (for each featureSet) = 12\n",
      "Iteration done in 0.03 [mins]\n",
      "Iteration done in 0.04 [mins]\n",
      "Iteration done in 0.05 [mins]\n",
      "Iteration done in 0.07 [mins]\n",
      "Iteration done in 0.06 [mins]\n",
      "Iteration done in 0.1 [mins]\n",
      "Iteration done in 0.13 [mins]\n",
      "Iteration done in 0.22 [mins]\n",
      "Iteration done in 0.19 [mins]\n",
      "Iteration done in 0.36 [mins]\n",
      "Iteration done in 0.29 [mins]\n",
      "Iteration done in 0.56 [mins]\n",
      "Congrats! All DONE. Total time is [mins]: 2.1\n",
      "All files were successfully saved to disk...\n",
      "\n",
      "Total iterations will be perform (for each featureSet) = 12\n",
      "Iteration done in 0.03 [mins]\n",
      "Iteration done in 0.04 [mins]\n",
      "Iteration done in 0.05 [mins]\n",
      "Iteration done in 0.08 [mins]\n",
      "Iteration done in 0.08 [mins]\n",
      "Iteration done in 0.12 [mins]\n",
      "Iteration done in 0.16 [mins]\n",
      "Iteration done in 0.27 [mins]\n",
      "Iteration done in 0.23 [mins]\n",
      "Iteration done in 0.45 [mins]\n",
      "Iteration done in 0.38 [mins]\n",
      "Iteration done in 0.79 [mins]\n",
      "Congrats! All DONE. Total time is [mins]: 2.68\n",
      "All files were successfully saved to disk...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RS = 100\n",
    "nSamples = len(dataRawTrain)\n",
    "nSplits = [2,4,6,10,15,20]\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "for dataset in datasetPack[:]:\n",
    "    cvs = [StratifiedKFold(n_splits=i, random_state=RS, shuffle=True) for i in nSplits]\n",
    "    \n",
    "    datasetMods = [\n",
    "        ['scaled', StandardScaler().fit_transform(dataset[:nSamples])],\n",
    "        ['non-scaled', dataset[:nSamples]]\n",
    "        ]\n",
    "\n",
    "    results = ccm.global_check_clf_models (datasetMods, dataRawTrain.Survived[:nSamples], scoring, cvs, RS, n_jobs = -1)#, debugMode=1)\n",
    "    ccm.postprocess_and_save_results(results, list(dataset.columns), cvs, datasetMods, path='checkClfModels/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
